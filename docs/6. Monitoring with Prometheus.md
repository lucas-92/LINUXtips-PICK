## Preparing the Cluster

Install eksctl:
```
curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv /tmp/eksctl /usr/local/bin
```

Install AWS CLI:
```
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install
```

Get your AWS Credentials:
- AWS Access Key ID
- AWS Secret Access Key
- Default region name
- Default output format

Configure your AWS Credentials:
```
aws configure
```

Create the cluster:
```
eksctl create cluster --name=eks-cluster --version=1.24 --region=us-east-1 --nodegroup-name=eks-cluster-nodegroup --node-type=t3.medium --nodes=2 --nodes-min=1 --nodes-max=3 --managed
```
- The above command will create an EKS cluster with the name eks-cluster, in the us-east-1 region, with 2 nodes of type t3.medium, and with a minimum of 1 node and a maximum of 3 nodes. Additionally, the above command will create a nodegroup called eks-cluster-nodegroup. eksctl will take care of all the infrastructure necessary for the operation of our EKS cluster. The version of Kubernetes that will be installed on our cluster will be 1.24.

Install kubectl:
```
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin/kubectl
```

Config kubectl to use EKS Cluster:
```
aws eks --region us-east-1 update-kubeconfig --name eks-cluster
```
- Where us-east-1 is the region of our EKS cluster, and eks-cluster is the name of our EKS cluster. This command is necessary so that kubectl knows which cluster it should use, it will take the credentials from our EKS cluster and store it in the ~/.kube/config file.

Testing:
```
kubectl get nodes
```

### eksctl Common Commands:

To list the EKS clusters we have in our account, simply run the following command. The -A parameter is to list EKS clusters from all regions:
```
eksctl get cluster -A
```

To list the EKS clusters for a specific region, simply run the following command:
```
eksctl get cluster -r us-east-1
```

To increase the number of nodes in our EKS cluster, simply run the following command:
```
eksctl scale nodegroup --cluster=eks-cluster --nodes=3 --nodes-min=1 --nodes-max=3 --name=eks-cluster-nodegroup -r us-east-1
```

To decrease the number of nodes in our EKS cluster, simply run the following command:
```
eksctl scale nodegroup --cluster=eks-cluster --nodes=1 --nodes-min=1 --nodes-max=3 --name=eks-cluster-nodegroup -r us-east-1
```

To delete our EKS cluster, simply run the following command:
```
eksctl delete cluster --name=eks-cluster -r us-east-1
```

## Installing Kube Prometheus

Kube Prometheus is distributed by the Prometheus Operator community. You can install it using the manifests available in the Prometheus Operator repository.

Clone the repository:
```
git clone https://github.com/prometheus-operator/kube-prometheus.git
cd kube-prometheus
```

Apply the namespace creation manifests and CRDs:
```
kubectl create -f manifests/setup
```

Wait until the CRDs are ready by checking their status:
```
kubectl get crds
```

Then, apply the rest of the manifests to install Prometheus, Grafana and Alertmanager:
```
kubectl create -f manifests/
```

Check the exposed services:
```
kubectl get svc -n monitoring
```

Expose Grafana with Port-Forward:
```
k port-forward -n monitoring svc/grafana 33000:3000
```

Expose Prometheus with Port-Forward:
```
k port-forward -n monitoring svc/prometheus-k8s 39090:9090
```

Expose Alertmanager with Port-Forward:
```
k port-forward -n monitoring svc/alertmanager-main 39393:9393
```

To see all created ServiceMonitor, simply run the following command:
```
k get servicemonitor -n monitoring
```

To see the contents of a ServiceMonitor, simply run the following command:
```
kubectl get servicemonitor prometheus-k8s -n monitoring -o yaml
```

To see custom resource definitions:
```
k get customresourcedefinitions
```
